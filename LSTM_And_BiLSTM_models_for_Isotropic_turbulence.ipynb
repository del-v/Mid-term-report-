{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM And BiLSTM models for Isotropic turbulence.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM Model for both datasets:**"
      ],
      "metadata": {
        "id": "o294vD3QqHVq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-5Wy166pBlO"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "\n",
        "#INput the POD mode value:\n",
        "mode=\n",
        "\n",
        "f = h5py.File('POD'+mode+'_isotropicTurb32BoxALL.mat')\n",
        "data = f.get('data')\n",
        "data = np.transpose(data)\n",
        "\n",
        "# Set User-defined params\n",
        "n_cells=250\n",
        "lr=0.0005\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "modelfilename = 'isoturb32boxROM_POD'+mode+'_c1.1.h5'\n",
        "lossfilename = 'isoturb32boxROM_POD'+mode+'_c1.1_res'\n",
        "\n",
        "length = 10\n",
        "output = 10\n",
        "\n",
        "\n",
        "# generate input and output pairs of sequences\n",
        "def create_sequences(data, length, output):\n",
        "    nsignals = data.shape[1]\n",
        "    siglen = data.shape[0]\n",
        "    sampX=[]\n",
        "    sampy=[]\n",
        "    indx = siglen - output - length\n",
        "    for j in range(nsignals):\n",
        "        sig = data[:,j]\n",
        "        for i in range(indx):\n",
        "            tempX = sig[i:length+i]\n",
        "            tempy = sig[i+length:length+i+output]\n",
        "            sampX.append(tempX)\n",
        "            sampy.append(tempy)\n",
        "    nsamples = len(sampX)        \n",
        "    X = np.array(sampX).reshape(nsamples, length, 1)\n",
        "    y = np.array(sampy).reshape(nsamples, output) \n",
        "    return X, y  \n",
        "\n",
        "#Split training and test datasets\n",
        "def define_test_dataset(X, y, n_patterns, ntestsigs):\n",
        "    testindex = int(np.floor(ntestsigs*n_patterns))\n",
        "    X_train = X[:-testindex,:,:]\n",
        "    y_train = y[:-testindex,:]\n",
        "    X_test = X[-testindex:,:,:]\n",
        "    y_test = y[-testindex:,:]\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "# configure problem\n",
        "nsignals = data.shape[1]\n",
        "siglen = data.shape[0]\n",
        "\n",
        "# Extract sequences\n",
        "inputdata = data[:,0:6]\n",
        "X, y = create_sequences(inputdata, length, output)\n",
        "#np.random.shuffle(X)\n",
        "#np.random.shuffle(y)\n",
        "ntestpatterns = siglen - length - output\n",
        "ntestsigs = 1\n",
        "X_train, y_train, X_test, y_test = define_test_dataset(X, y, ntestpatterns, ntestsigs)\n",
        "X_train.shape\n",
        "\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(n_cells, return_sequences=True, input_shape=(length, 1)))\n",
        "model.add(LSTM(n_cells))\n",
        "model.add(Dense(output))\n",
        "\n",
        "adam = optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "print(model.summary())\n",
        "\n",
        "# fit model\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "print('Saving weights..')\n",
        "#save weights for analysis\n",
        "model.save(modelfilename)\n",
        "\n",
        "loss_history =history.history['loss']\n",
        "\n",
        "\n",
        "# Save results to file\n",
        "print('Saving results')\n",
        "np.savez_compressed(lossfilename, batch_size=batch_size, epochs=epochs, loss_history=loss_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BiLSTM Model for Both datasets:**"
      ],
      "metadata": {
        "id": "tAF8aX7LqSy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Bidirectional\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "\n",
        "#INput the POD mode value:\n",
        "mode=\n",
        "f = h5py.File('POD'+mode+'_isotropicTurb32BoxALL.mat')\n",
        "data = f.get('data')\n",
        "data = np.transpose(data)\n",
        "\n",
        "# Set User-defined params\n",
        "n_cells=250\n",
        "lr=0.005\n",
        "batch_size = 32\n",
        "epochs = 75\n",
        "modelfilename = 'isoturb32boxROM_POD'+mode+'_c2.1.h5'\n",
        "lossfilename = 'isoturb32boxROM_POD'+mode+'_c2.1_res'\n",
        "\n",
        "length = 10\n",
        "output = 10\n",
        "\n",
        "\n",
        "# generate input and output pairs of sequences\n",
        "def create_sequences(data, length, output):\n",
        "    nsignals = data.shape[1]\n",
        "    siglen = data.shape[0]\n",
        "    sampX=[]\n",
        "    sampy=[]\n",
        "    indx = siglen - output - length\n",
        "    for j in range(nsignals):\n",
        "        sig = data[:,j]\n",
        "        for i in range(indx):\n",
        "            tempX = sig[i:length+i]\n",
        "            tempy = sig[i+length:length+i+output]\n",
        "            sampX.append(tempX)\n",
        "            sampy.append(tempy)\n",
        "    nsamples = len(sampX)        \n",
        "    X = np.array(sampX).reshape(nsamples, length, 1)\n",
        "    y = np.array(sampy).reshape(nsamples, output, 1) \n",
        "    return X, y  \n",
        "\n",
        "#Split training and test datasets\n",
        "def define_test_dataset(X, y, n_patterns, ntestsigs):\n",
        "    testindex = int(np.floor(ntestsigs*n_patterns))\n",
        "    X_train = X[:-testindex,:,:]\n",
        "    y_train = y[:-testindex,:,:]\n",
        "    X_test = X[-testindex:,:,:]\n",
        "    y_test = y[-testindex:,:,:]\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "# configure problem\n",
        "nsignals = data.shape[1]\n",
        "siglen = data.shape[0]\n",
        "\n",
        "# Extract sequences\n",
        "inputdata = data[:,0:6]\n",
        "X, y = create_sequences(inputdata, length, output)\n",
        "#np.random.shuffle(X)\n",
        "#np.random.shuffle(y)\n",
        "ntestpatterns = siglen - length - output\n",
        "ntestsigs = 1\n",
        "X_train, y_train, X_test, y_test = define_test_dataset(X, y, ntestpatterns, ntestsigs)\n",
        "X_train.shape\n",
        "\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(n_cells, return_sequences=True), input_shape=(length, 1)))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "adam = optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "model.compile(loss='mae', optimizer='adam')\n",
        "print(model.summary())\n",
        "\n",
        "# fit model\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "print('Saving weights..')\n",
        "#save weights for analysis\n",
        "model.save(modelfilename)\n",
        "\n",
        "loss_history =history.history['loss']\n",
        "\n",
        "\n",
        "# Save results to file\n",
        "print('Saving results')\n",
        "np.savez_compressed(lossfilename, batch_size=batch_size, epochs=epochs, loss_history=loss_history)"
      ],
      "metadata": {
        "id": "wjNR01_9p3O5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}